import asyncio
import aiohttp
import base64
import io
import logging
import re
import traceback
from typing import Dict, Any, Optional, List
from PIL import Image
from config import Config

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SuperAgent:
    """çµ±åˆã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ãƒ†ã‚­ã‚¹ãƒˆ&ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«&ãƒªã‚µãƒ¼ãƒå¯¾å¿œ"""
    
    def __init__(self):
        self.config = Config()
        self.base_url = self.config.OLLAMA_BASE_URL
        
        # ä¼šè©±å±¥æ­´ç®¡ç†
        self.conversation_history = []
        self.max_history_length = 10  # æœ€å¤§ä¿æŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
        self.context_window = 5  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°
        
        # ãƒªã‚µãƒ¼ãƒã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰
        self.research_engine = None
        try:
            from research import FreeResearchEngine
            self.research_engine = FreeResearchEngine()
            logger.info("âœ… Research engine initialized successfully")
        except ImportError as e:
            logger.warning(f"âš ï¸ Research module not available: {e}")
        except Exception as e:
            logger.error(f"âŒ Error initializing research engine: {e}")
    
    def add_to_history(self, role: str, content: str, metadata: Optional[Dict] = None):
        """ä¼šè©±å±¥æ­´ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        message = {
            "role": role,
            "content": content,
            "timestamp": traceback.format_exc() if role == "error" else None,
            "metadata": metadata or {}
        }
        
        self.conversation_history.append(message)
        
        # å±¥æ­´ã®é•·ã•ã‚’åˆ¶é™
        if len(self.conversation_history) > self.max_history_length * 2:  # user + assistant ã®ãƒšã‚¢
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]
        
        logger.info(f"Added message to history: {role} - {len(content)} chars")

    def get_conversation_context(self) -> str:
        """ä¼šè©±ã®æ–‡è„ˆã‚’å–å¾—"""
        if not self.conversation_history:
            return ""
        
        context_messages = self.conversation_history[-self.context_window * 2:]  # æœ€æ–°ã®Nå›ã®å¯¾è©±
        context = "## ğŸ“ ä¼šè©±å±¥æ­´\n\n"
        
        for msg in context_messages:
            role_emoji = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–"
            content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
            context += f"{role_emoji} **{msg['role'].title()}**: {content}\n\n"
        
        context += "---\n\n"
        return context

    def extract_key_information(self, messages: List[Dict]) -> str:
        """é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã¦è¦ç´„"""
        if not messages:
            return ""
        
        key_info = []
        for msg in messages:
            content = msg.get("content", "")
            
            # é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
            important_keywords = [
                "åå‰", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ", "è¨­å®š", "ã‚¨ãƒ©ãƒ¼", "å•é¡Œ", "è§£æ±º", 
                "é‡è¦", "æ³¨æ„", "è¦šãˆã¦", "è¨˜æ†¶", "ä¿å­˜", "ãƒ•ã‚¡ã‚¤ãƒ«"
            ]
            
            if any(keyword in content for keyword in important_keywords):
                summary = content[:100] + "..." if len(content) > 100 else content
                key_info.append(f"â€¢ {summary}")
        
        if key_info:
            return "## ğŸ”‘ é‡è¦ãªæƒ…å ±\n\n" + "\n".join(key_info) + "\n\n"
        return ""

    def update_model_settings(self, model: str, temperature: float):
        """ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°ï¼ˆå¤–éƒ¨ã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ï¼‰"""
        logger.info(f"Model settings updated: {model}, temperature: {temperature}")
        # å¿…è¦ã«å¿œã˜ã¦è¨­å®šã‚’ä¿å­˜
        self.add_to_history("system", f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°: {model}, æ¸©åº¦: {temperature}")

    def _analyze_task_type(self, text: str, has_image: bool = False) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ†æï¼ˆè©³ç´°ãƒ­ã‚°ä»˜ãï¼‰"""
        logger.info(f"Analyzing task type for: '{text[:50]}...' (has_image: {has_image})")
        
        text_lower = text.lower()
        
        # ãƒªã‚µãƒ¼ãƒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        research_keywords = [
            "èª¿ã¹ã¦", "ç ”ç©¶", "æƒ…å ±", "æœ€æ–°", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "è«–æ–‡", "ãƒ‡ãƒ¼ã‚¿", 
            "åˆ†æã—ã¦", "è©³ã—ã", "æ¤œç´¢", "ãƒªã‚µãƒ¼ãƒ", "èª¿æŸ»", "äº‹å®Ÿ", "çµ±è¨ˆ"
        ]
        
        if has_image:
            # ç”»åƒå‡¦ç†ã‚¿ã‚¹ã‚¯
            for task_type in ["vision_ocr", "vision_analysis", "vision_description"]:
                keywords = self.config.TASK_KEYWORDS.get(task_type, [])
                if any(keyword in text_lower for keyword in keywords):
                    logger.info(f"Task type determined: {task_type}")
                    return task_type
            logger.info("Task type determined: vision_description (default)")
            return "vision_description"
        else:
            # ãƒªã‚µãƒ¼ãƒåˆ¤å®š
            if self.research_engine and any(keyword in text_lower for keyword in research_keywords):
                logger.info("Task type determined: research")
                return "research"
            
            # ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†åˆ¤å®š
            for task_type in ["reasoning", "creative"]:
                keywords = self.config.TASK_KEYWORDS.get(task_type, [])
                if any(keyword in text_lower for keyword in keywords):
                    logger.info(f"Task type determined: {task_type}")
                    return task_type
            
            logger.info("Task type determined: general (default)")
            return "general"
    
    def _optimize_image(self, image: Image.Image) -> str:
        """ç”»åƒã‚’æœ€é©åŒ–ã—ã¦base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        logger.info("Optimizing image...")
        try:
            # ã‚µã‚¤ã‚ºèª¿æ•´
            max_size = self.config.IMAGE_MAX_SIZE
            if max(image.size) > max_size:
                ratio = max_size / max(image.size)
                new_size = tuple(int(dim * ratio) for dim in image.size)
                image = image.resize(new_size, Image.Resampling.LANCZOS)
                logger.info(f"Image resized to {new_size}")
            
            # RGBå¤‰æ›
            if image.mode != 'RGB':
                if image.mode in ('RGBA', 'LA'):
                    background = Image.new('RGB', image.size, (255, 255, 255))
                    if image.mode == 'RGBA':
                        background.paste(image, mask=image.split()[-1])
                    else:
                        background.paste(image)
                    image = background
                else:
                    image = image.convert('RGB')
                logger.info("Image converted to RGB")
            
            # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=self.config.IMAGE_QUALITY, optimize=True)
            encoded = base64.b64encode(buffer.getvalue()).decode('utf-8')
            logger.info(f"Image encoded (base64 length: {len(encoded)})")
            return encoded
            
        except Exception as e:
            logger.error(f"Image optimization error: {e}")
            raise
    
    def _create_prompt(self, query: str, task_type: str, research_data: Optional[Dict] = None) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆä¼šè©±å±¥æ­´ä»˜ãï¼‰"""
        logger.info(f"Creating prompt for task type: {task_type}")
        
        # ä¼šè©±å±¥æ­´ã‚’å«ã‚ã‚‹
        conversation_context = self.get_conversation_context()
        key_information = self.extract_key_information(self.conversation_history)
        
        base_prompt = f"{conversation_context}{key_information}**ç¾åœ¨ã®è³ªå•**: {query}\n\n"
        
        # ãƒªã‚µãƒ¼ãƒã‚¿ã‚¹ã‚¯ã®å ´åˆ
        if task_type == "research" and research_data:
            research_summary = self._generate_research_summary(research_data)
            logger.info("Created research-based prompt")
            return f"""
{conversation_context}{key_information}

ã‚ãªãŸã¯æƒ…å ±åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ãªãŒã‚‰ã€ä»¥ä¸‹ã®ãƒªã‚µãƒ¼ãƒçµæœã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«è©³ç´°ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query}

ãƒªã‚µãƒ¼ãƒçµæœ:
{research_summary}

ä»¥ä¸‹ã®æ§‹é€ ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
1. **è¦ç´„**: é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®æ¦‚è¦
2. **è©³ç´°åˆ†æ**: å„æƒ…å ±æºã‹ã‚‰ã®çŸ¥è¦‹
3. **ä¼šè©±ã®æ–‡è„ˆ**: éå»ã®å¯¾è©±ã¨ã®é–¢é€£æ€§
4. **ä¿¡é ¼æ€§è©•ä¾¡**: æƒ…å ±ã®ä¿¡é ¼åº¦ã¨æ ¹æ‹ 
5. **è¿½åŠ ã®è€ƒå¯Ÿ**: å°‚é–€çš„ãªåˆ†æã¨è¦‹è§£
6. **é–¢é€£æƒ…å ±**: ã•ã‚‰ã«èª¿ã¹ã‚‹ã¹ãç‚¹

å®¢è¦³çš„ã§åˆ†æçš„ãªå›ç­”ã‚’å¿ƒãŒã‘ã€ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦æƒ…å ±æºã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚
"""
        
        # ãã®ä»–ã®ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—
        prompts = {
            "reasoning": base_prompt + """
ã‚ãªãŸã¯è«–ç†çš„æ€è€ƒã®å°‚é–€å®¶ã§ã™ã€‚ä¼šè©±å±¥æ­´ã‚’å‚è€ƒã«ã—ãªãŒã‚‰ã€ä»¥ä¸‹ã®æ‰‹é †ã§è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ï¼š
1. éå»ã®å¯¾è©±ã¨ã®é–¢é€£æ€§ã®ç¢ºèª
2. å•é¡Œã®æœ¬è³ªçš„ãªç†è§£
3. é–¢é€£è¦å› ã®åˆ†æ  
4. æ®µéšçš„ãªæ¨è«–éç¨‹
5. è«–ç†çš„ãªçµè«–
æ€è€ƒéç¨‹ã‚’æ˜ç¢ºã«ç¤ºã—ã€ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚
""",
            "creative": base_prompt + """
ã‚ãªãŸã¯å‰µé€ æ€§è±Šã‹ãªå°‚é–€å®¶ã§ã™ã€‚ä¼šè©±å±¥æ­´ã®ãƒ†ãƒ¼ãƒã‚„é›°å›²æ°—ã‚’æ´»ã‹ã—ãªãŒã‚‰ã€ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚ã¦å‰µä½œã—ã¦ãã ã•ã„ï¼š
1. éå»ã®å¯¾è©±ã§è¨€åŠã•ã‚ŒãŸãƒ†ãƒ¼ãƒã®æ´»ç”¨
2. ç‹¬å‰µçš„ãªã‚¢ã‚¤ãƒ‡ã‚¢
3. é®®æ˜ã§ç¾ã—ã„æå†™
4. æ„Ÿæƒ…ã«è¨´ãˆã‚‹è¡¨ç¾
5. å®Ÿç”¨çš„ãªææ¡ˆ
è‡ªç”±ã§é­…åŠ›çš„ãªç™ºæƒ³ã‚’å±•é–‹ã—ã€ä¼šè©±ã®ç¶™ç¶šæ€§ã‚’ä¿ã£ã¦ãã ã•ã„ã€‚
""",
            "general": base_prompt + """
ã‚ãªãŸã¯å¹…åºƒã„çŸ¥è­˜ã‚’æŒã¤å°‚é–€å®¶ã§ã™ã€‚ä¼šè©±å±¥æ­´ã‚’è¸ã¾ãˆã¦ã€ä»¥ä¸‹ã‚’å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
1. éå»ã®å¯¾è©±ã¨ã®é–¢é€£æ€§
2. æ­£ç¢ºã§è©³ç´°ãªæƒ…å ±
3. å…·ä½“çš„ãªä¾‹
4. å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹
5. æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
åˆ†ã‹ã‚Šã‚„ã™ãå®Ÿç”¨çš„ã«èª¬æ˜ã—ã€ä¼šè©±ã®æµã‚Œã‚’æ„è­˜ã—ã¦ãã ã•ã„ã€‚
""",
            "vision_description": base_prompt + """
ç”»åƒã‚’è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€éå»ã®å¯¾è©±ã§è¨€åŠã•ã‚ŒãŸå†…å®¹ã¨ã®é–¢é€£ãŒã‚ã‚Œã°æŒ‡æ‘˜ã—ã¦ãã ã•ã„ï¼š
1. å…¨ä½“çš„ãªæ§‹å›³ã¨ä¸»è¦ç´ 
2. è‰²å½©ã€é›°å›²æ°—ã€è³ªæ„Ÿ
3. äººç‰©ã€ç‰©ä½“ã€é¢¨æ™¯ã®è©³ç´°
4. å ´æ‰€ã‚„æ™‚é–“ã®æ¨æ¸¬
5. å°è±¡çš„ãªç‰¹å¾´
6. ä¼šè©±å±¥æ­´ã¨ã®é–¢é€£æ€§
""",
            "vision_analysis": base_prompt + """
ç”»åƒã‚’å°‚é–€çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚éå»ã®å¯¾è©±å†…å®¹ã‚‚è€ƒæ…®ã«å…¥ã‚Œã¦ãã ã•ã„ï¼š
1. æŠ€è¡“çš„ç‰¹å¾´ã¨æ‰‹æ³•
2. æ§‹æˆè¦ç´ ã®è©³ç´°åˆ†æ
3. èƒŒæ™¯æƒ…å ±ã¨æ–‡è„ˆ
4. ç‰¹ç­†ã™ã¹ãè¦ç´ 
5. å°‚é–€çš„ãªè€ƒå¯Ÿ
6. ä¼šè©±å±¥æ­´ã¨ã®é–¢é€£åˆ†æ
""",
            "vision_ocr": base_prompt + """
ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£ç¢ºã«èª­ã¿å–ã£ã¦ãã ã•ã„ã€‚éå»ã®å¯¾è©±ã§é–¢é€£ã™ã‚‹å†…å®¹ãŒã‚ã‚Œã°è¨€åŠã—ã¦ãã ã•ã„ï¼š
1. æ–‡å­—ã®æ­£ç¢ºãªæ–‡å­—èµ·ã“ã—
2. ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ§‹é€ ã®ä¿æŒ
3. èª­ã¿å–ã‚Œãªã„éƒ¨åˆ†ã®æ˜è¨˜
4. è¨€èªã®é©åˆ‡ãªèªè­˜
5. ä¼šè©±å±¥æ­´ã¨ã®é–¢é€£æ€§
"""
        }
        
        prompt = prompts.get(task_type, prompts["general"])
        logger.info(f"Created prompt with context (length: {len(prompt)})")
        return prompt
    
    def _generate_research_summary(self, research_data: Dict[str, Any]) -> str:
        """ãƒªã‚µãƒ¼ãƒçµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        logger.info("Generating research summary...")
        if not research_data:
            logger.warning("No research data available")
            return ""
        
        query = research_data["query"]
        results = research_data["results"]
        sources = research_data["sources_used"]
        
        summary = f"# ğŸ“Š '{query}' ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒªã‚µãƒ¼ãƒçµæœ\n\n"
        summary += f"**æ¤œç´¢å®Ÿè¡Œæ™‚åˆ»**: {research_data['timestamp']}\n"
        summary += f"**æ¤œç´¢æ™‚é–“**: {research_data['research_duration']:.2f}ç§’\n"
        summary += f"**æƒ…å ±æº**: {', '.join(sources)}\n"
        summary += f"**åé›†ã—ãŸæƒ…å ±æ•°**: {research_data['total_results']}ä»¶\n\n"
        
        summary += "## ğŸ” ä¸»è¦ãªç™ºè¦‹\n\n"
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†
        by_source = {}
        for result in results:
            source = result["source"]
            if source not in by_source:
                by_source[source] = []
            by_source[source].append(result)
        
        for source, source_results in by_source.items():
            summary += f"### {source}\n\n"
            for result in source_results[:3]:  # å„ã‚½ãƒ¼ã‚¹ã‹ã‚‰ä¸Šä½3ä»¶
                summary += f"**{result['title']}**\n"
                summary += f"{result['snippet']}\n"
                if result.get('url'):
                    summary += f"ğŸ”— [è©³ç´°]({result['url']})\n\n"
        
        logger.info(f"Generated summary (length: {len(summary)})")
        return summary
    
    def _select_model(self, task_type: str) -> str:
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
        logger.info(f"Selecting model for task type: {task_type}")
        model_mapping = {
            "research": self.config.MODELS["reasoning"],  # åˆ†æåŠ›ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«
            "reasoning": self.config.MODELS["reasoning"],
            "creative": self.config.MODELS["creative"], 
            "general": self.config.MODELS["general"],
            "vision_description": self.config.MODELS["vision"],
            "vision_analysis": self.config.MODELS.get("vision_detailed", self.config.MODELS["vision"]),
            "vision_ocr": self.config.MODELS.get("vision_fast", self.config.MODELS["vision"])
        }
        model = model_mapping.get(task_type, self.config.MODELS["general"])
        logger.info(f"Selected model: {model}")
        return model
    
    def _get_temperature(self, task_type: str) -> float:
        """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦æ¸©åº¦ã‚’è¨­å®š"""
        logger.info(f"Setting temperature for task type: {task_type}")
        temperatures = {
            "research": 0.3,
            "reasoning": 0.1,
            "general": 0.7,
            "creative": 0.9,
            "vision_description": 0.7,
            "vision_analysis": 0.3,
            "vision_ocr": 0.1
        }
        temp = temperatures.get(task_type, 0.7)
        logger.info(f"Temperature set to: {temp}")
        return temp
    
    async def _call_api(self, model: str, prompt: str, image_base64: Optional[str] = None, temperature: float = 0.7) -> Dict[str, Any]:
        """Ollama APIå‘¼ã³å‡ºã—"""
        url = f"{self.base_url}/api/chat"
        logger.info(f"Calling Ollama API: {url}")
        
        message = {"role": "user", "content": prompt}
        if image_base64:
            message["images"] = [image_base64]
            logger.info("Image included in API call")
        
        payload = {
            "model": model,
            "messages": [message],
            "stream": False,
            "options": {
                "temperature": temperature,
                "top_p": 0.9,
                "num_predict": 2048
            }
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, timeout=self.config.OLLAMA_TIMEOUT) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info("API call successful")
                        return {
                            "success": True,
                            "response": result.get("message", {}).get("content", "å¿œç­”ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"),
                            "model_info": {
                                "model": result.get("model", model),
                                "eval_count": result.get("eval_count", 0),
                                "total_duration": result.get("total_duration", 0)
                            }
                        }
                    else:
                        error_text = await response.text()
                        logger.error(f"API error: {response.status} - {error_text}")
                        return {
                            "success": False,
                            "response": f"APIã‚¨ãƒ©ãƒ¼: {error_text}",
                            "error": f"Status {response.status}"
                        }
        except Exception as e:
            logger.error(f"API call error: {e}")
            return {
                "success": False,
                "response": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "error": str(e)
            }
    
    async def process_query(self, text: str, image: Optional[Image.Image] = None, conversation_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """ãƒ¡ã‚¤ãƒ³ã®å‡¦ç†é–¢æ•°ï¼ˆä¼šè©±å±¥æ­´å¯¾å¿œï¼‰"""
        logger.info(f"Processing query: '{text[:100]}...'")
        
        # å¤–éƒ¨ã‹ã‚‰ä¼šè©±å±¥æ­´ã‚’å—ã‘å–ã‚‹å ´åˆ
        if conversation_history:
            self.conversation_history = conversation_history[-self.max_history_length * 2:]
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
        self.add_to_history("user", text, {"has_image": image is not None})
        
        try:
            # ã‚¿ã‚¹ã‚¯åˆ†æ
            task_type = self._analyze_task_type(text, image is not None)
            logger.info(f"Task type: {task_type}")
            
            research_data = None
            
            # ãƒªã‚µãƒ¼ãƒå®Ÿè¡Œ
            if task_type == "research" and self.research_engine:
                logger.info("Starting deep research...")
                try:
                    research_data = await self.research_engine.conduct_deep_research(text)
                    logger.info(f"Research completed: {research_data['total_results']} results")
                except Exception as e:
                    logger.error(f"Research failed: {e}")
                    task_type = "reasoning"  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    logger.info(f"Fallback to task type: {task_type}")
            
            # ãƒ¢ãƒ‡ãƒ«é¸æŠ
            model = self._select_model(task_type)
            temperature = self._get_temperature(task_type)
            logger.info(f"Selected model: {model}, temperature: {temperature}")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = self._create_prompt(text, task_type, research_data)
            logger.info(f"Prompt created (length: {len(prompt)})")
            
            # ç”»åƒå‡¦ç†
            image_base64 = None
            if image:
                image_base64 = self._optimize_image(image)
                logger.info(f"Image optimized (base64 length: {len(image_base64)})")
            
            # APIå‘¼ã³å‡ºã—
            logger.info("Calling Ollama API...")
            result = await self._call_api(model, prompt, image_base64, temperature)
            logger.info(f"API call completed: success={result['success']}")
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
            if result["success"]:
                self.add_to_history("assistant", result["response"], {
                    "task_type": task_type,
                    "model": model,
                    "temperature": temperature
                })
            
            return {
                "task_type": task_type,
                "response": result["response"],
                "success": result["success"],
                "has_image": image is not None,
                "research_data": research_data,
                "conversation_history": self.conversation_history,
                "model_info": {
                    "model": model,
                    "temperature": temperature,
                    **result.get("model_info", {})
                }
            }
            
        except Exception as e:
            logger.error(f"Error in process_query: {type(e).__name__}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            
            # ã‚¨ãƒ©ãƒ¼ã‚’å±¥æ­´ã«è¿½åŠ 
            self.add_to_history("error", f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            return {
                "task_type": "error",
                "response": f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}",
                "success": False,
                "has_image": image is not None,
                "conversation_history": self.conversation_history,
                "model_info": {"model": "error", "temperature": 0}
            } 
import streamlit as st
import asyncio
import json
import os
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Union
from PIL import Image
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from agents import SuperAgent
from config import Config
from data_analysis import DataAnalyzer

# åŸºæœ¬è¨­å®š
config = Config()
st.set_page_config(**config.PAGE_CONFIG)

# Ollamaãƒ¢ãƒ‡ãƒ«è¨­å®š
MODEL_CONFIGS = {
    "deepseek-r1:14b": {
        "name": "DeepSeek R1 14B",
        "description": "é«˜åº¦ãªæ¨è«–èƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã€‚è¤‡é›‘ãªåˆ†æã¨å•é¡Œè§£æ±ºã«æœ€é©ã€‚",
        "recommended_tasks": ["reasoning", "analysis", "research"],
        "max_tokens": 4096,
        "temperature_range": (0.0, 1.5)
    },
    "gemma3:latest": {
        "name": "Gemma 3",
        "description": "å‰µé€ çš„ãªã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚æ–‡ç« ä½œæˆã¨å‰µä½œã«æœ€é©ã€‚",
        "recommended_tasks": ["creative", "writing", "chat"],
        "max_tokens": 2048,
        "temperature_range": (0.0, 2.0)
    },
    "llava:latest": {
        "name": "LLaVA",
        "description": "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚ç”»åƒç†è§£ã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ä¸¡æ–¹ã«å¯¾å¿œã€‚",
        "recommended_tasks": ["vision", "analysis", "chat"],
        "max_tokens": 2048,
        "temperature_range": (0.0, 1.0)
    },
    "llava:13b": {
        "name": "LLaVA 13B",
        "description": "å¤§å‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚è©³ç´°ãªç”»åƒåˆ†æã«æœ€é©ã€‚",
        "recommended_tasks": ["vision", "analysis", "reasoning"],
        "max_tokens": 4096,
        "temperature_range": (0.0, 1.0)
    },
    "moondream:latest": {
        "name": "Moondream",
        "description": "è»½é‡ã§é«˜é€Ÿãªç”»åƒç†è§£ãƒ¢ãƒ‡ãƒ«ã€‚åŸºæœ¬çš„ãªç”»åƒå‡¦ç†ã«æœ€é©ã€‚",
        "recommended_tasks": ["vision", "chat"],
        "max_tokens": 1024,
        "temperature_range": (0.0, 1.0)
    },
    "qwen2.5:latest": {
        "name": "Qwen 2.5",
        "description": "é«˜æ€§èƒ½ãªå¤šè¨€èªãƒ¢ãƒ‡ãƒ«ã€‚ç¿»è¨³ã¨è¦ç´„ã«å„ªã‚ŒãŸæ€§èƒ½ã€‚",
        "recommended_tasks": ["translation", "summarization", "chat"],
        "max_tokens": 8192,
        "temperature_range": (0.0, 1.5)
    }
}

# ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã®å®šç¾©
TASK_TYPES = {
    "chat": "ä¸€èˆ¬çš„ãªä¼šè©±",
    "creative": "å‰µé€ çš„ãªæ–‡ç« ç”Ÿæˆ",
    "analysis": "ãƒ‡ãƒ¼ã‚¿åˆ†æã¨è§£é‡ˆ",
    "research": "ãƒªã‚µãƒ¼ãƒã¨æƒ…å ±åé›†",
    "summarization": "è¦ç´„ã¨æ•´ç†",
    "translation": "ç¿»è¨³",
    "reasoning": "è«–ç†çš„æ¨è«–",
    "writing": "æ–‡ç« ä½œæˆ",
    "vision": "ç”»åƒç†è§£ãƒ»å‡¦ç†"
}

# å±¥æ­´ç®¡ç†ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
HISTORY_DIR = "chat_histories"
os.makedirs(HISTORY_DIR, exist_ok=True)

# çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
STATS_DIR = "usage_stats"
os.makedirs(STATS_DIR, exist_ok=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "agent" not in st.session_state:
    st.session_state.agent = SuperAgent()
if "processing" not in st.session_state:
    st.session_state.processing = False
if "search_query" not in st.session_state:
    st.session_state.search_query = ""
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "deepseek-r1:14b"
if "temperature" not in st.session_state:
    st.session_state.temperature = 0.7
if "task_type" not in st.session_state:
    st.session_state.task_type = "chat"
if "data_analyzer" not in st.session_state:
    st.session_state.data_analyzer = DataAnalyzer()
if "stats" not in st.session_state:
    st.session_state.stats = {
        "total_requests": 0,
        "model_usage": {},
        "response_times": [],
        "errors": 0,
        "daily_usage": {},
        "hourly_usage": {}
    }

def get_recommended_models(task_type: str) -> List[str]:
    """ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
    recommended = []
    for model_id, config in MODEL_CONFIGS.items():
        if task_type in config["recommended_tasks"]:
            recommended.append(model_id)
    return recommended

def update_model_settings():
    """ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°"""
    st.session_state.agent.update_model_settings(
        model=st.session_state.selected_model,
        temperature=st.session_state.temperature
    )

def save_conversation(messages: List[Dict[str, Any]], filename: str):
    """ä¼šè©±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    try:
        data = {
            "timestamp": datetime.now().isoformat(),
            "message_count": len(messages),
            "messages": messages
        }
        filepath = os.path.join(HISTORY_DIR, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False

def load_conversation(filename: str) -> Optional[List[Dict[str, Any]]]:
    """ä¼šè©±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿"""
    try:
        filepath = os.path.join(HISTORY_DIR, filename)
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data.get("messages", [])
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def search_messages(query: str) -> List[Dict[str, Any]]:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œç´¢"""
    if not query:
        return st.session_state.messages
    
    query = query.lower()
    results = []
    for message in st.session_state.messages:
        content = message.get("content", "").lower()
        if query in content:
            results.append(message)
    return results

def delete_message(index: int):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤"""
    if 0 <= index < len(st.session_state.messages):
        st.session_state.messages.pop(index)
        st.rerun()

def save_stats():
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
    try:
        filepath = os.path.join(STATS_DIR, "usage_stats.json")
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(st.session_state.stats, f, ensure_ascii=False, indent=2)
    except Exception as e:
        st.error(f"çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def load_stats():
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        filepath = os.path.join(STATS_DIR, "usage_stats.json")
        if os.path.exists(filepath):
            with open(filepath, "r", encoding="utf-8") as f:
                st.session_state.stats = json.load(f)
    except Exception as e:
        st.error(f"çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def update_stats(result: Dict[str, Any], response_time: float, is_error: bool = False):
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
    stats = st.session_state.stats
    
    # åŸºæœ¬çµ±è¨ˆ
    stats["total_requests"] += 1
    if is_error:
        stats["errors"] += 1
    
    # ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å›æ•°
    model = result.get("model_info", {}).get("model", "unknown")
    stats["model_usage"][model] = stats["model_usage"].get(model, 0) + 1
    
    # å¿œç­”æ™‚é–“
    stats["response_times"].append(response_time)
    
    # æ—¥æ™‚åˆ¥ä½¿ç”¨é‡
    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    hour_str = now.strftime("%H:00")
    
    stats["daily_usage"][date_str] = stats["daily_usage"].get(date_str, 0) + 1
    stats["hourly_usage"][hour_str] = stats["hourly_usage"].get(hour_str, 0) + 1
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    save_stats()

def create_usage_graph(data: Dict[str, int], title: str, xaxis_title: str):
    """ä½¿ç”¨é‡ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    df = pd.DataFrame(list(data.items()), columns=["time", "count"])
    df = df.sort_values("time")
    
    fig = px.bar(
        df,
        x="time",
        y="count",
        title=title,
        labels={"time": xaxis_title, "count": "ä½¿ç”¨å›æ•°"}
    )
    
    fig.update_layout(
        xaxis_title=xaxis_title,
        yaxis_title="ä½¿ç”¨å›æ•°",
        showlegend=False
    )
    
    return fig

def create_model_usage_pie():
    """ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å›æ•°ã®å††ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    model_usage = st.session_state.stats["model_usage"]
    if not model_usage:
        return None
    
    fig = px.pie(
        values=list(model_usage.values()),
        names=list(model_usage.keys()),
        title="ãƒ¢ãƒ‡ãƒ«åˆ¥ä½¿ç”¨å›æ•°"
    )
    
    return fig

def show_statistics():
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    stats = st.session_state.stats
    
    # åŸºæœ¬çµ±è¨ˆ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°", stats["total_requests"])
    
    with col2:
        error_rate = (stats["errors"] / stats["total_requests"] * 100) if stats["total_requests"] > 0 else 0
        st.metric("ã‚¨ãƒ©ãƒ¼ç‡", f"{error_rate:.1f}%")
    
    with col3:
        avg_response_time = sum(stats["response_times"]) / len(stats["response_times"]) if stats["response_times"] else 0
        st.metric("å¹³å‡å¿œç­”æ™‚é–“", f"{avg_response_time:.1f}ç§’")
    
    with col4:
        unique_models = len(stats["model_usage"])
        st.metric("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æ•°", unique_models)
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    col1, col2 = st.columns(2)
    
    with col1:
        # æ—¥åˆ¥ä½¿ç”¨é‡
        daily_fig = create_usage_graph(
            stats["daily_usage"],
            "æ—¥åˆ¥ä½¿ç”¨é‡",
            "æ—¥ä»˜"
        )
        st.plotly_chart(daily_fig, use_container_width=True)
        
        # æ™‚é–“åˆ¥ä½¿ç”¨é‡
        hourly_fig = create_usage_graph(
            stats["hourly_usage"],
            "æ™‚é–“åˆ¥ä½¿ç”¨é‡",
            "æ™‚é–“"
        )
        st.plotly_chart(hourly_fig, use_container_width=True)
    
    with col2:
        # ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨å›æ•°
        model_fig = create_model_usage_pie()
        if model_fig:
            st.plotly_chart(model_fig, use_container_width=True)
        
        # å¿œç­”æ™‚é–“ã®åˆ†å¸ƒ
        if stats["response_times"]:
            response_times_df = pd.DataFrame(stats["response_times"], columns=["response_time"])
            fig = px.histogram(
                response_times_df,
                x="response_time",
                title="å¿œç­”æ™‚é–“ã®åˆ†å¸ƒ",
                labels={"response_time": "å¿œç­”æ™‚é–“ï¼ˆç§’ï¼‰", "count": "å›æ•°"}
            )
            st.plotly_chart(fig, use_container_width=True)

def analyze_data(data: Union[pd.DataFrame, str, List[Dict[str, Any]]], analysis_type: str = "basic"):
    """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œ
    
    Args:
        data: åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
        analysis_type: åˆ†æã‚¿ã‚¤ãƒ— ('basic', 'correlation', 'visualization')
    """
    analyzer = st.session_state.data_analyzer
    analyzer.load_data(data)
    
    results = {}
    if analysis_type == "basic":
        results = analyzer.basic_statistics()
    elif analysis_type == "correlation":
        results = analyzer.correlation_analysis()
    
    return results

def show_data_analysis_interface():
    """ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’è¡¨ç¤º"""
    st.subheader("ãƒ‡ãƒ¼ã‚¿åˆ†æ")
    
    # ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
    data_input = st.text_area("ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼ˆJSONå½¢å¼ï¼‰", height=200)
    
    if data_input:
        try:
            # ãƒ‡ãƒ¼ã‚¿ã®è§£æ
            analysis_type = st.selectbox(
                "åˆ†æã‚¿ã‚¤ãƒ—",
                ["basic", "correlation", "visualization"]
            )
            
            if st.button("åˆ†æå®Ÿè¡Œ"):
                results = analyze_data(data_input, analysis_type)
                
                if "error" in results:
                    st.error(results["error"])
                else:
                    st.json(results)
                    
                    # å¯è¦–åŒ–ã®è¡¨ç¤º
                    if analysis_type == "visualization":
                        plot_type = st.selectbox(
                            "ãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒ—",
                            ["scatter", "line", "bar", "histogram"]
                        )
                        if st.button("ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ"):
                            plot_result = st.session_state.data_analyzer.create_visualization(
                                plot_type=plot_type
                            )
                            if "plot" in plot_result:
                                st.plotly_chart(json.loads(plot_result["plot"]))
                            else:
                                st.error(plot_result.get("error", "ãƒ—ãƒ­ãƒƒãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"))
        
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def main():
    st.title("ğŸ¤– ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    st.markdown("ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« + ãƒ‡ã‚£ãƒ¼ãƒ—ãƒªã‚µãƒ¼ãƒå¯¾å¿œAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # çµ±è¨ˆã‚¿ãƒ–
        tab1, tab2 = st.tabs(["ãƒ¢ãƒ‡ãƒ«è¨­å®š", "ä½¿ç”¨çµ±è¨ˆ"])
        
        with tab1:
            # ãƒ¢ãƒ‡ãƒ«è¨­å®š
            st.subheader("ğŸ¤– ãƒ¢ãƒ‡ãƒ«è¨­å®š")
            
            # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—é¸æŠ
            task_type = st.selectbox(
                "ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
                options=list(TASK_TYPES.keys()),
                format_func=lambda x: TASK_TYPES[x],
                key="task_type"
            )
            
            # æ¨å¥¨ãƒ¢ãƒ‡ãƒ«è¡¨ç¤º
            recommended_models = get_recommended_models(task_type)
            if recommended_models:
                st.info("æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: " + ", ".join(MODEL_CONFIGS[m]["name"] for m in recommended_models))
            
            # ãƒ¢ãƒ‡ãƒ«é¸æŠ
            selected_model = st.selectbox(
                "ãƒ¢ãƒ‡ãƒ«",
                options=list(MODEL_CONFIGS.keys()),
                format_func=lambda x: MODEL_CONFIGS[x]["name"],
                key="selected_model"
            )
            
            # ãƒ¢ãƒ‡ãƒ«è©³ç´°è¡¨ç¤º
            model_config = MODEL_CONFIGS[selected_model]
            with st.expander("ãƒ¢ãƒ‡ãƒ«è©³ç´°"):
                st.write(f"**èª¬æ˜**: {model_config['description']}")
                st.write(f"**æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°**: {model_config['max_tokens']:,}")
                st.write("**æ¨å¥¨ã‚¿ã‚¹ã‚¯**:")
                for task in model_config["recommended_tasks"]:
                    st.write(f"- {TASK_TYPES[task]}")
            
            # æ¸©åº¦è¨­å®š
            temp_range = model_config["temperature_range"]
            temperature = st.slider(
                "æ¸©åº¦ (å‰µé€ æ€§)",
                min_value=temp_range[0],
                max_value=temp_range[1],
                value=st.session_state.temperature,
                step=0.1,
                help="é«˜ã„ã»ã©å‰µé€ çš„ã€ä½ã„ã»ã©æ±ºå®šè«–çš„ãªå¿œç­”ã«ãªã‚Šã¾ã™",
                key="temperature"
            )
            
            # è¨­å®šé©ç”¨ãƒœã‚¿ãƒ³
            if st.button("âš¡ è¨­å®šã‚’é©ç”¨"):
                update_model_settings()
                st.success("ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")
            
            st.divider()
            
            # ä¼šè©±è¨˜æ†¶è¨­å®š
            st.subheader("ğŸ§  ä¼šè©±è¨˜æ†¶è¨­å®š")
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶çŠ¶æ³è¡¨ç¤º
            if hasattr(st.session_state.agent, 'conversation_history'):
                agent_memory_count = len(st.session_state.agent.conversation_history)
                st.metric("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨˜æ†¶æ•°", agent_memory_count)
                
                # è¨˜æ†¶ã®å†…å®¹ã‚’è¡¨ç¤º
                if agent_memory_count > 0:
                    with st.expander("ğŸ” è¨˜æ†¶å†…å®¹ã‚’ç¢ºèª"):
                        for i, msg in enumerate(st.session_state.agent.conversation_history[-6:]):  # æœ€æ–°6ä»¶
                            role_emoji = "ğŸ‘¤" if msg["role"] == "user" else "ğŸ¤–" if msg["role"] == "assistant" else "âš™ï¸"
                            content_preview = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
                            st.write(f"{role_emoji} **{msg['role']}**: {content_preview}")
                
                # è¨˜æ†¶ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
                if st.button("ğŸ§¹ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨˜æ†¶ã‚’ã‚¯ãƒªã‚¢"):
                    st.session_state.agent.conversation_history = []
                    st.success("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
                    st.rerun()
            
            st.divider()
            
            # æ¤œç´¢æ©Ÿèƒ½
            st.subheader("ğŸ” å±¥æ­´æ¤œç´¢")
            search_query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", key="search_input")
            if search_query:
                st.session_state.search_query = search_query
            
            # çµ±è¨ˆ
            message_count = len(st.session_state.messages)
            st.metric("å¯¾è©±å›æ•°", message_count // 2)
            
            # å±¥æ­´ç®¡ç†
            st.subheader("ğŸ’¾ å±¥æ­´ç®¡ç†")
            
            # ä¿å­˜
            if message_count > 0:
                save_name = st.text_input("ä¿å­˜å", value=f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
                if st.button("ğŸ’¾ ä¼šè©±ã‚’ä¿å­˜"):
                    if save_conversation(st.session_state.messages, f"{save_name}.json"):
                        st.success("ä¿å­˜ã—ã¾ã—ãŸ")
            
            # èª­ã¿è¾¼ã¿
            st.subheader("ğŸ“‚ ä¿å­˜æ¸ˆã¿ä¼šè©±")
            saved_files = [f for f in os.listdir(HISTORY_DIR) if f.endswith(".json")]
            if saved_files:
                selected_file = st.selectbox("èª­ã¿è¾¼ã‚€ä¼šè©±ã‚’é¸æŠ", saved_files)
                if st.button("ğŸ“– ä¼šè©±ã‚’èª­ã¿è¾¼ã¿"):
                    messages = load_conversation(selected_file)
                    if messages:
                        st.session_state.messages = messages
                        st.success("èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                        st.rerun()
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ/ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            st.subheader("ğŸ“¤ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ/ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            if message_count > 0:
                export_data = {
                    "timestamp": datetime.now().isoformat(),
                    "message_count": message_count,
                    "messages": st.session_state.messages
                }
                st.download_button(
                    "ğŸ“¤ JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
                    data=json.dumps(export_data, ensure_ascii=False, indent=2),
                    file_name=f"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
            
            # ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            uploaded_file = st.file_uploader("ğŸ“¥ JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆ", type=["json"])
            if uploaded_file:
                try:
                    data = json.load(uploaded_file)
                    if st.button("ğŸ“¥ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ"):
                        if "messages" in data:
                            st.session_state.messages = data["messages"]
                            st.success("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
                            st.rerun()
                except Exception as e:
                    st.error(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            
            # ãƒªã‚»ãƒƒãƒˆ
            if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢"):
                st.session_state.messages = []
                st.rerun()

        with tab2:
            show_statistics()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    messages_to_display = search_messages(st.session_state.search_query)
    for i, message in enumerate(messages_to_display):
        with st.chat_message(message["role"]):
            col1, col2 = st.columns([20, 1])
            with col1:
                st.write(message["content"])
                if message.get("image"):
                    st.image(message["image"])
            with col2:
                if st.button("ğŸ—‘ï¸", key=f"delete_{i}"):
                    delete_message(i)
                    st.rerun()

    # å…¥åŠ›ã‚¨ãƒªã‚¢
    col1, col2 = st.columns([3, 1])

    with col1:
        user_input = st.chat_input(
            "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..." if not st.session_state.processing else "å‡¦ç†ä¸­...",
            disabled=st.session_state.processing
        )

    with col2:
        uploaded_file = st.file_uploader(
            "ğŸ“· ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['png', 'jpg', 'jpeg'],
            disabled=st.session_state.processing
        )

    # å‡¦ç†
    if user_input and not st.session_state.processing:
        try:
            st.session_state.processing = True
            start_time = datetime.now()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ 
            user_message = {"role": "user", "content": user_input}
            if uploaded_file:
                image = Image.open(uploaded_file)
                user_message["image"] = image
            st.session_state.messages.append(user_message)
            
            # AIå¿œç­”ç”Ÿæˆï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å‡¦ç†ï¼‰
            with st.spinner("ğŸ¤” å‡¦ç†ä¸­..."):
                result = asyncio.run(
                    st.session_state.agent.process_query(
                        user_input,
                        image if uploaded_file else None,
                        conversation_history=st.session_state.messages
                    )
                )
            
            # çµ±è¨ˆæ›´æ–°
            end_time = datetime.now()
            response_time = (end_time - start_time).total_seconds()
            update_stats(result, response_time)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
            assistant_message = {
                "role": "assistant",
                "content": result.get("response", "å¿œç­”ãªã—"),
                "task_type": result.get("task_type", "unknown"),
                "model_info": result.get("model_info", {}),
                "has_image": result.get("has_image", False),
                "research_data": result.get("research_data")
            }
            st.session_state.messages.append(assistant_message)
            
            st.session_state.processing = False
            st.rerun()
            
        except Exception as e:
            st.session_state.processing = False
            
            # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆæ›´æ–°
            end_time = datetime.now()
            response_time = (end_time - start_time).total_seconds()
            update_stats({"model_info": {"model": "error"}}, response_time, is_error=True)
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜
            error_message = {
                "role": "assistant",
                "content": f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "task_type": "error",
                "model_info": {"model": "error"}
            }
            st.session_state.messages.append(error_message)
            st.rerun()

if __name__ == "__main__":
    main() 